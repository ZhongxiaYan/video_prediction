{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T07:32:45.807677",
     "start_time": "2017-05-06T00:32:45.793659-07:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import random\n",
    "from scipy.misc import imread\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T07:32:46.341952",
     "start_time": "2017-05-06T00:32:45.966162-07:00"
    },
    "code_folding": [
     45
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lrelu(x, alpha):\n",
    "    return tf.maximum(x, alpha*x)\n",
    "\n",
    "def conv(x, filter_size, num_filters, stride, name, padding='SAME', groups=1, trainable=True):\n",
    "    input_channels = int(x.get_shape()[-1])\n",
    "\n",
    "    # Create lambda function for the convolution\n",
    "    convolve = lambda x, W: tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding=padding)\n",
    "\n",
    "    with tf.variable_scope(name):\n",
    "        # Create tf variables for the weights and biases of the conv layer\n",
    "        regularizer = tf.contrib.layers.l2_regularizer(1e-5)\n",
    "        weights = tf.get_variable('W',\n",
    "                                  shape=[filter_size, filter_size, input_channels // groups, num_filters],\n",
    "                                  initializer=tf.contrib.layers.xavier_initializer(), regularizer = regularizer,\n",
    "                                  trainable=trainable)\n",
    "        biases = tf.get_variable('b', shape=[num_filters], trainable=trainable, initializer=tf.zeros_initializer())\n",
    "\n",
    "        if groups == 1:\n",
    "            conv = convolve(x, weights)\n",
    "\n",
    "        else:\n",
    "            # Split input and weights and convolve them separately\n",
    "            input_groups = tf.split(x, groups, axis=3)\n",
    "            weight_groups = tf.split(weights, groups, axis=3)\n",
    "            output_groups = [convolve(i, k) for i, k in zip(input_groups, weight_groups)]\n",
    "\n",
    "            # Concat the convolved output together again\n",
    "            conv = tf.concat(output_groups, axis=3)\n",
    "\n",
    "        return lrelu(conv + biases, 0.01)\n",
    "\n",
    "def deconv_layer(x, filter_size, num_filters, stride, name, padding='SAME', relu=True):\n",
    "    activation = None\n",
    "    if relu:\n",
    "        activation = tf.nn.relu\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(1e-5)\n",
    "    return tf.layers.conv2d_transpose(x, num_filters, filter_size, stride, padding=padding, kernel_initializer=tf.contrib.layers.xavier_initializer(), kernel_regularizer=regularizer, activation=activation, name=name)\n",
    "    \n",
    "def fc(x, num_out, name, relu=True, trainable=True):\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(1e-5)\n",
    "    num_in = int(x.get_shape()[-1])\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('W', shape=[num_in, num_out], regularizer=regularizer, initializer=tf.contrib.layers.xavier_initializer(), trainable=trainable)\n",
    "        biases = tf.get_variable('b', [num_out], initializer=tf.zeros_initializer(), trainable=trainable)\n",
    "        x = tf.matmul(x, weights) + biases\n",
    "        if relu:\n",
    "            x = lrelu(x, 0.01) \n",
    "    return x\n",
    "\n",
    "def lrn(x, radius, alpha, beta, name, bias=1.0):\n",
    "    return tf.nn.local_response_normalization(x, depth_radius=radius, alpha=alpha, beta=beta, bias=bias, name=name)\n",
    "\n",
    "def max_pool(x, filter_size, stride, name=None, padding='SAME'):\n",
    "    return tf.nn.max_pool(x, ksize=[1, filter_size, filter_size, 1], strides=[1, stride, stride, 1], padding=padding, name=name)\n",
    "\n",
    "def dropout(x, keep_prob):\n",
    "    return tf.nn.dropout(x, keep_prob)\n",
    "\n",
    "def vgg(input, keep_prob=0.5, process_input=True):\n",
    "    if process_input:\n",
    "        #VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "        VGG_MEAN = 103.939\n",
    "        \"\"\"\n",
    "        # Convert RGB to BGR and subtract mean\n",
    "        red, green, blue = tf.split(input, 3, axis=3)\n",
    "        input = tf.concat([\n",
    "            blue - VGG_MEAN[0],\n",
    "            green - VGG_MEAN[1],\n",
    "            red - VGG_MEAN[2],\n",
    "        ], axis=3)\n",
    "        \"\"\"\n",
    "        input = input - VGG_MEAN\n",
    "\n",
    "    pool_ = lambda x: max_pool(x, 2, 2)\n",
    "    conv_ = lambda x, output_depth, name: conv(x, 3, output_depth, 1, name=name)\n",
    "    \n",
    "    conv_1_1 = conv_(tf.concat([input,input,input], axis = -1), 64, 'conv1_1')\n",
    "    conv_1_2 = conv_(conv_1_1, 64, 'conv1_2')\n",
    "    print(conv_1_2.shape)\n",
    "    pool_1 = pool_(conv_1_2)\n",
    "\n",
    "    conv_2_1 = conv_(pool_1, 128, 'conv2_1')\n",
    "    conv_2_2 = conv_(conv_2_1, 128, 'conv2_2')\n",
    "    print(conv_2_2.shape)\n",
    "    pool_2 = pool_(conv_2_2)\n",
    "\n",
    "    conv_3_1 = conv_(pool_2, 256, 'conv3_1')\n",
    "    conv_3_2 = conv_(conv_3_1, 256, 'conv3_2')\n",
    "    conv_3_3 = conv_(conv_3_2, 256, 'conv3_3')\n",
    "    print(conv_3_3.shape)\n",
    "    pool_3 = pool_(conv_3_3)\n",
    "\n",
    "    conv_4_1 = conv_(pool_3, 512, 'conv4_1')\n",
    "    conv_4_2 = conv_(conv_4_1, 512, 'conv4_2')\n",
    "    conv_4_3 = conv_(conv_4_2, 512, 'conv4_3')\n",
    "    print(conv_4_3.shape)\n",
    "    pool_4 = pool_(conv_4_3)\n",
    "\n",
    "    conv_5_1 = conv_(pool_4, 512, 'conv5_1')\n",
    "    conv_5_2 = conv_(conv_5_1, 512, 'conv5_2')\n",
    "    conv_5_3 = conv_(conv_5_2, 512, 'conv5_3')\n",
    "    print(conv_5_3.shape)\n",
    "    pool_5 = pool_(conv_5_3)\n",
    "    flattened = tf.contrib.layers.flatten(pool_5)\n",
    "\n",
    "    fc_6 = dropout(fc(flattened, 4096, 'fc6'), keep_prob)\n",
    "    fc_7 = fc(fc_6, 4096, 'fc7', relu=False)\n",
    "    return conv_1_2, conv_2_2, conv_3_3, conv_4_3, conv_5_3, fc_7\n",
    "\n",
    "def vgg_simple(input, keep_prob = 0.5):\n",
    "    pool_ = lambda x: max_pool(x, 2, 2)\n",
    "    conv_ = lambda x, output_depth, name: conv(x, 3, output_depth, 1, name=name)\n",
    "    \n",
    "    conv_1_1 = conv_(input, 16, 'conv1_1')\n",
    "    pool_1 = pool_(conv_1_1)\n",
    "\n",
    "    conv_2_1 = conv_(pool_1, 32, 'conv2_1')\n",
    "    pool_2 = pool_(conv_2_1)\n",
    "\n",
    "    conv_3_1 = conv_(pool_2, 64, 'conv3_1')\n",
    "    pool_3 = pool_(conv_3_1)\n",
    "\n",
    "    conv_4_1 = conv_(pool_3, 64, 'conv4_1')\n",
    "    pool_4 = pool_(conv_4_1)\n",
    "\n",
    "    conv_5_1 = conv_(pool_4, 64, 'conv5_1')\n",
    "    pool_5 = pool_(conv_5_1)\n",
    "    \n",
    "    flattened = tf.contrib.layers.flatten(pool_5)\n",
    "    fc_6 = dropout(fc(flattened, 4096, 'fc6'), keep_prob)\n",
    "    fc_7 = fc(fc_6, 4096, 'fc7', relu=False)\n",
    "    return fc_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T07:36:57.533285",
     "start_time": "2017-05-06T00:36:56.650191-07:00"
    },
    "code_folding": [
     51
    ]
   },
   "outputs": [],
   "source": [
    "class Generator(object):\n",
    "    def __init__(self):\n",
    "        self.train_variables = []\n",
    "        self.has_defined_layers = False\n",
    "        self.has_defined_C1 = False\n",
    "        self.has_defined_vgg_ = False\n",
    "    \n",
    "    def init_network(self, discriminator):\n",
    "        self.p_t_n = tf.placeholder(tf.float32, [None, 224, 224,L])\n",
    "        self.p_t = tf.placeholder(tf.float32, [None, 224, 224,L])\n",
    "        self.x_t = tf.placeholder(tf.float32, [None, 224, 224, 1])\n",
    "        self.x_t_n = tf.placeholder(tf.float32, [None, 224, 224, 1])\n",
    "        self.x_t_n_predicted = self.get_output_tensor(self.p_t_n, self.p_t, self.x_t)\n",
    "        self.x_t_n_test = self.get_output_tensor(self.p_t_n, self.p_t, self.x_t, 1.0)\n",
    "        mean_l2 = lambda x, y: tf.reduce_mean(tf.squared_difference(x, y))\n",
    "        self.l2_loss = tf.check_numerics(mean_l2(self.x_t_n, self.x_t_n_predicted), \"l2\")\n",
    "        self.feat_loss = tf.check_numerics(mean_l2(self.C1(self.x_t), self.C1(self.x_t_n_predicted)), \"feat\")\n",
    "#         feat_loss = mean_l2(self.C1(self.x_t), self.C1(self.x_t_n_predicted))+mean_l2(self.vgg(self.x_t), self.vgg(self.x_t_n_predicted))\n",
    "        self.adv_loss = tf.check_numerics(-tf.reduce_mean(tf.log(discriminator.get_output_tensor(self.x_t_n_predicted, self.p_t_n))), \"adv\")\n",
    "        self.loss = 1*self.l2_loss + 0.1*self.feat_loss + 0.1*self.adv_loss\n",
    "        self.opt = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(self.loss, var_list=self.train_variables)\n",
    "        \n",
    "    def get_output_tensor(self, p_t_n, p_t, x_t, keep_prob = 0.5):\n",
    "        with tf.variable_scope('generator', reuse=self.has_defined_layers):\n",
    "            p_t_n_latent = self.f_pose(p_t_n, keep_prob)\n",
    "            conv_1, conv_2, conv_3, conv_4, conv_5, fc_7 = self.f_img(x_t, keep_prob)\n",
    "#             latent = p_t_n_latent - self.f_pose(p_t, force_reuse=True) + self.f_img(x_t)\n",
    "            latent = tf.concat((p_t_n_latent, self.f_pose(p_t, keep_prob, force_reuse=True), fc_7), axis = 1)\n",
    "            output = self.f_dec(latent, conv_5, conv_4, conv_3, conv_2, conv_1)\n",
    "        if not self.has_defined_layers:\n",
    "            self.train_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='generator')\n",
    "        self.has_defined_layers = True\n",
    "        return output\n",
    "        \n",
    "    def f_pose(self, input, keep_prob, force_reuse=False):\n",
    "        '''\n",
    "        Applies f_pose function to the input tensor to get an output. Should be similar to VGG architecture\n",
    "        '''\n",
    "        with tf.variable_scope('f_pose', reuse=(self.has_defined_layers or force_reuse)):\n",
    "            return vgg_simple(input, keep_prob)\n",
    "        \n",
    "    def f_img(self, input, keep_prob):\n",
    "        '''\n",
    "        Applies f_img function to the input tensor to get an output. Should be exactly VGG architecture\n",
    "        '''\n",
    "        with tf.variable_scope('f_img', reuse=self.has_defined_layers):\n",
    "            return vgg(input, keep_prob, process_input=True)\n",
    "        \n",
    "    def f_dec(self, input, conv_5, conv_4, conv_3, conv_2, conv_1):\n",
    "        '''\n",
    "        Applies f_dec function to the input tensor to get an output.\n",
    "        '''\n",
    "        with tf.variable_scope('f_dec', reuse=self.has_defined_layers):\n",
    "            reshaped = tf.reshape(input, shape=[tf.shape(input)[0], 1, 1, 4096*3])\n",
    "            deconv_6_1 = deconv_layer(reshaped, 7, 128, 1, 'deconv6_1', padding='VALID')\n",
    "            \n",
    "#             deconv_5_3 = tf.concat([deconv_layer(deconv_6_1, 3, 128, 2, 'deconv5_3'), conv_5], axis = -1)\n",
    "            deconv_5_3 = deconv_layer(deconv_6_1, 3, 128, 2, 'deconv5_3')\n",
    "            deconv_5_2 = deconv_layer(deconv_5_3, 3, 128, 1, 'deconv5_2')\n",
    "            deconv_5_1 = deconv_layer(deconv_5_2, 3, 128, 2, 'deconv5_1')\n",
    "            print(\"deconv: \", deconv_5_3.shape)\n",
    "#             deconv_4_3 = tf.concat([deconv_layer(deconv_5_1, 3, 128, 1, 'deconv4_3'), conv_4], axis = -1)\n",
    "            deconv_4_3 = deconv_layer(deconv_5_1, 3, 128, 1, 'deconv4_3')\n",
    "            deconv_4_2 = deconv_layer(deconv_4_3, 3, 128, 1, 'deconv4_2')\n",
    "            deconv_4_1 = deconv_layer(deconv_4_2, 3, 64, 2, 'deconv4_1')\n",
    "            print(\"deconv: \", deconv_4_3.shape)\n",
    "            deconv_3_3 = tf.concat([deconv_layer(deconv_4_1, 3, 64, 1, 'deconv3_3'), conv_3], axis = -1)\n",
    "            deconv_3_2 = deconv_layer(deconv_3_3, 3, 64, 1, 'deconv3_2')\n",
    "            deconv_3_1 = deconv_layer(deconv_3_2, 3, 32, 2, 'deconv3_1')\n",
    "            print(\"deconv: \", deconv_3_3.shape)\n",
    "#             deconv_2_2 = tf.concat([deconv_layer(deconv_3_1, 3, 32, 1, 'deconv2_2'), conv_2], axis = -1)\n",
    "            deconv_2_2 = deconv_layer(deconv_3_1, 3, 32, 1, 'deconv2_2')\n",
    "            deconv_2_1 = deconv_layer(deconv_2_2, 3, 16, 2, 'deconv2_1')\n",
    "            print(\"deconv: \", deconv_2_2.shape)\n",
    "#             deconv_1_2 = tf.concat([deconv_layer(deconv_2_1, 3, 16, 1, 'deconv1_2'), conv_1], axis = -1)\n",
    "            deconv_1_2 = deconv_layer(deconv_2_1, 3, 16, 1, 'deconv1_2')\n",
    "            deconv_1_1 = deconv_layer(deconv_1_2, 3, 1, 1, 'deconv1_1')\n",
    "            print(\"deconv: \", deconv_1_2.shape)\n",
    "        return deconv_1_1\n",
    "        \n",
    "    def C1(self, input):\n",
    "        input = tf.image.resize_images(input, [227, 227])\n",
    "        with tf.variable_scope('C1', reuse=self.has_defined_C1):\n",
    "            conv1 = conv(tf.concat([input,input,input], axis=-1), 11, 96, 4, padding='VALID', name='conv1', trainable=False)\n",
    "            pool1 = max_pool(conv1, 3, 2, padding='VALID', name='pool1')\n",
    "            norm1 = lrn(pool1, 2, 2e-5, 0.75, name='norm1')\n",
    "\n",
    "            conv2 = conv(norm1, 5, 256, 1, groups=2, name='conv2', trainable=False)\n",
    "            pool2 = max_pool(conv2, 3, 2, padding='VALID', name='pool2')\n",
    "            norm2 = lrn(pool2, 2, 2e-5, 0.75, name='norm2')\n",
    "\n",
    "            conv3 = conv(norm2, 3, 384, 1, name='conv3', trainable=False)\n",
    "            conv4 = conv(conv3, 3, 384, 1, groups=2, name='conv4', trainable=False)\n",
    "            conv5 = conv(conv4, 3, 256, 1, groups=2, name='conv5', trainable=False)\n",
    "        self.has_defined_C1 = True\n",
    "        return conv5\n",
    "    \n",
    "#     def vgg(self, input):\n",
    "#         with tf.variable_scope('f_vgg', reuse=self.has_defined_vgg_):\n",
    "#             self.has_defined_vgg_ = True\n",
    "#             return vgg(input, process_input=True)\n",
    "\n",
    "\n",
    "    def init_weights(self, sess, alexnet_file, vgg_file):\n",
    "        weights_dict = np.load(alexnet_file, encoding='bytes').item()\n",
    "        with tf.variable_scope('C1', reuse=True):\n",
    "            for layer in ['conv1', 'conv2', 'conv3', 'conv4', 'conv5']:\n",
    "                with tf.variable_scope(layer):\n",
    "                    W_value, b_value = weights_dict[layer]\n",
    "                    W = tf.get_variable('W', trainable=False)\n",
    "                    b = tf.get_variable('b', trainable=False)\n",
    "                    sess.run(W.assign(W_value))\n",
    "                    sess.run(b.assign(b_value))\n",
    "        weights_dict = np.load(vgg_file, encoding='bytes').item()\n",
    "        weights_dict = { key.decode('ascii') : value for key, value in weights_dict.items() }\n",
    "        with tf.variable_scope('generator/f_img', reuse=True):\n",
    "            for layer in ['conv1_1', 'conv1_2',\n",
    "                          'conv2_1', 'conv2_2',\n",
    "                          'conv3_1', 'conv3_2', 'conv3_3',\n",
    "                          'conv4_1', 'conv4_2', 'conv4_3',\n",
    "                          'conv5_1', 'conv5_2', 'conv5_3',\n",
    "                          'fc6', 'fc7']:\n",
    "                with tf.variable_scope(layer):\n",
    "                    W_value, b_value = weights_dict[layer]\n",
    "                    W = tf.get_variable('W')\n",
    "                    b = tf.get_variable('b')\n",
    "                    sess.run(W.assign(W_value))\n",
    "                    sess.run(b.assign(b_value))\n",
    "\n",
    "    def fit_batch(self, sess, p_t, p_t_n, x_t, x_t_n):\n",
    "        _, loss = sess.run((self.opt, self.loss), feed_dict={ self.p_t : p_t, self.p_t_n : p_t_n, self.x_t : x_t, self.x_t_n : x_t_n })\n",
    "        return loss\n",
    "    def test_batch(self, sess, p_t, p_t_n, x_t, x_t_n):\n",
    "        output = sess.run((self.x_t_n_test), feed_dict={ self.p_t : p_t, self.p_t_n : p_t_n, self.x_t : x_t, self.x_t_n : x_t_n  })\n",
    "        return output\n",
    "    #def test_gen(self, sess, p_t, p_t_n, x_t):\n",
    "        \n",
    "\n",
    "class Discriminator(object):\n",
    "    def __init__(self):\n",
    "        self.train_variables = []\n",
    "        self.has_defined_layers = False\n",
    "    \n",
    "    def init_network(self, discriminator):\n",
    "        self.p_t = tf.placeholder(tf.float32, [None, 224, 224,L])\n",
    "        self.p_t_n = tf.placeholder(tf.float32, [None, 224, 224,L])\n",
    "        self.x_t = tf.placeholder(tf.float32, [None, 224, 224, 1])\n",
    "        self.x_t_n = tf.placeholder(tf.float32, shape=[None, 224, 224, 1])\n",
    "        x_t_n_real = self.x_t_n\n",
    "        x_t_n_pred = generator.get_output_tensor(self.p_t_n, self.p_t, self.x_t)\n",
    "\n",
    "        real_prob = self.get_output_tensor(x_t_n_real, self.p_t_n)\n",
    "        fake_prob = self.get_output_tensor(x_t_n_pred, self.p_t_n)\n",
    "        real_mismatch_prob = self.get_output_tensor(self.x_t, self.p_t_n)\n",
    "        \n",
    "        self.loss = -tf.reduce_mean(tf.log(tf.maximum(0.001,real_prob)) + 0.5 * tf.log(1.001 - fake_prob) + 0.5 * tf.log(1.001 - real_mismatch_prob))\n",
    "        self.opt = tf.train.GradientDescentOptimizer(learning_rate=5e-3).minimize(self.loss, var_list=self.train_variables)\n",
    "#         self.check_op = tf.add_check_numerics_ops()\n",
    "        \n",
    "    def get_output_tensor(self, x, p):\n",
    "        with tf.variable_scope('discriminator', reuse=self.has_defined_layers):\n",
    "            with tf.variable_scope('f_img'):\n",
    "                conv_1, conv_2, conv_3, conv_4, conv_5, vgg_x = vgg(x)\n",
    "            with tf.variable_scope('f_pose'):\n",
    "                vgg_p = vgg_simple(p)\n",
    "            concat = tf.concat([vgg_x, vgg_p], axis=1)\n",
    "            fc8 = fc(concat, 4096, name='fc8')\n",
    "            output = tf.nn.sigmoid(fc(fc8, 1, name='fc9', relu=False))\n",
    "        if not self.has_defined_layers:\n",
    "            self.train_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='discriminator')\n",
    "        self.has_defined_layers = True\n",
    "        return output\n",
    "    \n",
    "    def init_weights(self, sess, alexnet_file, vgg_file):\n",
    "        weights_dict = np.load(vgg_file, encoding='bytes').item()\n",
    "        weights_dict = { key.decode('ascii') : value for key, value in weights_dict.items() }\n",
    "        with tf.variable_scope('discriminator/f_img', reuse=True):\n",
    "            for layer in ['conv1_1', 'conv1_2',\n",
    "                          'conv2_1', 'conv2_2',\n",
    "                          'conv3_1', 'conv3_2', 'conv3_3',\n",
    "                          'conv4_1', 'conv4_2', 'conv4_3',\n",
    "                          'conv5_1', 'conv5_2', 'conv5_3',\n",
    "                          'fc6', 'fc7']:\n",
    "                with tf.variable_scope(layer):\n",
    "                    W_value, b_value = weights_dict[layer]\n",
    "                    W = tf.get_variable('W')\n",
    "                    b = tf.get_variable('b')\n",
    "                    sess.run(W.assign(W_value))\n",
    "                    sess.run(b.assign(b_value))\n",
    "    \n",
    "    def fit_batch(self, sess, p_t, p_t_n, x_t, x_t_n):\n",
    "        _, loss = sess.run((self.opt, self.loss), feed_dict={ self.p_t : p_t, self.p_t_n : p_t_n, self.x_t : x_t, self.x_t_n : x_t_n })\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T07:36:57.685450",
     "start_time": "2017-05-06T00:36:57.536783-07:00"
    },
    "code_folding": [],
    "collapsed": true,
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def restore(generator, discriminator, checkpoint):\n",
    "    var_list = generator.train_variables + discriminator.train_variables\n",
    "#     saver = tf.train.Saver(var_list={var.name.split(':')[0].replace(, 'alexnet') : var for var in var_list})\n",
    "    saver.restore(sess, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-05-06T07:36:57.792490",
     "start_time": "2017-05-06T00:36:57.689950-07:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-05-06T07:36:58.137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 224, 224, 64)\n",
      "(?, 112, 112, 128)\n",
      "(?, 56, 56, 256)\n",
      "(?, 28, 28, 512)\n",
      "(?, 14, 14, 512)\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(128)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(128)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(56), Dimension(56), Dimension(320)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(112), Dimension(112), Dimension(32)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(224), Dimension(224), Dimension(16)]))\n",
      "(?, 224, 224, 64)\n",
      "(?, 112, 112, 128)\n",
      "(?, 56, 56, 256)\n",
      "(?, 28, 28, 512)\n",
      "(?, 14, 14, 512)\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(128)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(128)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(56), Dimension(56), Dimension(320)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(112), Dimension(112), Dimension(32)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(224), Dimension(224), Dimension(16)]))\n",
      "(?, 224, 224, 64)\n",
      "(?, 112, 112, 128)\n",
      "(?, 56, 56, 256)\n",
      "(?, 28, 28, 512)\n",
      "(?, 14, 14, 512)\n",
      "(?, 224, 224, 64)\n",
      "(?, 112, 112, 128)\n",
      "(?, 56, 56, 256)\n",
      "(?, 28, 28, 512)\n",
      "(?, 14, 14, 512)\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(14), Dimension(14), Dimension(128)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(28), Dimension(28), Dimension(128)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(56), Dimension(56), Dimension(320)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(112), Dimension(112), Dimension(32)]))\n",
      "('deconv: ', TensorShape([Dimension(None), Dimension(224), Dimension(224), Dimension(16)]))\n",
      "(?, 224, 224, 64)\n",
      "(?, 112, 112, 128)\n",
      "(?, 56, 56, 256)\n",
      "(?, 28, 28, 512)\n",
      "(?, 14, 14, 512)\n",
      "(?, 224, 224, 64)\n",
      "(?, 112, 112, 128)\n",
      "(?, 56, 56, 256)\n",
      "(?, 28, 28, 512)\n",
      "(?, 14, 14, 512)\n",
      "(?, 224, 224, 64)\n",
      "(?, 112, 112, 128)\n",
      "(?, 56, 56, 256)\n",
      "(?, 28, 28, 512)\n",
      "(?, 14, 14, 512)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "generator.init_network(discriminator)\n",
    "discriminator.init_network(generator)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "generator.init_weights(sess, 'models/alexnet.npy', 'models/vgg16.npy')\n",
    "discriminator.init_weights(sess, 'models/alexnet.npy', 'models/vgg16.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dictionary of squat videos. \n",
    "# Key = video number, Value = list of frames (numpy array images) of video\n",
    "\n",
    "# mod 0-8 for training, mod 9 for test\n",
    "def process_videos(mod):\n",
    "    videos = {}\n",
    "    videos_test = {}\n",
    "    i = 0\n",
    "    for video in os.listdir('squats/'):\n",
    "        if i % 9 != mod:\n",
    "            videos[video] = []\n",
    "            for frame in os.listdir('squats/' + str(video) + '/'):\n",
    "                filename = 'squats/' + str(video) + '/' + str(frame)\n",
    "                videos[video].append(imread(filename, flatten=True).reshape((224,224,1)).astype('uint8'))\n",
    "        else:\n",
    "            videos_test[video] = []\n",
    "            for frame in os.listdir('squats/' + str(video) + '/'):\n",
    "                filename = 'squats/' + str(video) + '/' + str(frame)\n",
    "                videos_test[video].append(imread(filename, flatten=True).reshape((224,224,1)).astype('uint8'))\n",
    "        i = i + 1\n",
    "\n",
    "    # Create dictionary of heatmat labels for squat videos. \n",
    "    # For L = 13\n",
    "    # Key = video number, Value = list of stack of joints (numpy array images (224x224x13))\n",
    "    if L == 13:\n",
    "        labels = {}\n",
    "        labels_test = {}\n",
    "        for video in os.listdir('squats_labels_multiple/'):\n",
    "            if video in videos:\n",
    "                labels[video] = []\n",
    "                for frame in os.listdir('squats_labels_multiple/' + str(video) + '/'):\n",
    "                    frame_folder = 'squats_labels_multiple/' + str(video) + '/' + str(frame) + '/'\n",
    "                    temp_image_stack = np.zeros((224,224,13)).astype('uint8')\n",
    "                    for i in range(13):\n",
    "                        temp_image_stack[:,:,i] = imread(frame_folder + str(i)+ '.jpg').astype('uint8')\n",
    "                    labels[video].append(temp_image_stack)\n",
    "            elif video in videos_test:\n",
    "                labels_test[video] = []\n",
    "                for frame in os.listdir('squats_labels_multiple/' + str(video) + '/'):\n",
    "                    frame_folder = 'squats_labels_multiple/' + str(video) + '/' + str(frame) + '/'\n",
    "                    temp_image_stack = np.zeros((224,224,13)).astype('uint8')\n",
    "                    for i in range(13):\n",
    "                        temp_image_stack[:,:,i] = imread(frame_folder + str(i)+ '.jpg').astype('uint8')\n",
    "                    labels_test[video].append(temp_image_stack)\n",
    "\n",
    "    # For L = 1 \n",
    "    # Key = video number, Value = list of heatmaps for each frame (numpy array images (224x224x1))            \n",
    "    elif L == 1:\n",
    "        labels = {}\n",
    "        labels_test = {}\n",
    "        for video in os.listdir('squats_labels/'):\n",
    "            if video in videos:\n",
    "                labels[video] = []\n",
    "                for frame in os.listdir('squats_labels/' + str(video) + '/'):\n",
    "                    filename = 'squats_labels/' + str(video) + '/' + str(frame)\n",
    "                    labels[video].append(imread(filename).reshape((224,224,1)))\n",
    "            elif video in videos_test:\n",
    "                labels_test[video] = []\n",
    "                for frame in os.listdir('squats_labels/' + str(video) + '/'):\n",
    "                    filename = 'squats_labels/' + str(video) + '/' + str(frame)\n",
    "                    labels_test[video].append(imread(filename).reshape((224,224,1)))\n",
    "    return videos, videos_test, labels, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_minibatch(batch_size):\n",
    "    frames1 = []\n",
    "    heatmaps1 = []\n",
    "    frames2 = []\n",
    "    heatmaps2 = []\n",
    "    for i in range(batch_size):\n",
    "        rand_video = videos.keys()[random.randint(0,len(videos.keys())-1)]\n",
    "        \n",
    "        rand_int = random.randint(0,len(videos[rand_video])-1)\n",
    "        frames1.append(videos[rand_video][rand_int])\n",
    "        heatmaps1.append(labels[rand_video][rand_int])\n",
    "\n",
    "        rand_int = random.randint(0,len(videos[rand_video])-1)\n",
    "        frames2.append(videos[rand_video][rand_int])\n",
    "        heatmaps2.append(labels[rand_video][rand_int])\n",
    "    return frames1, frames2, heatmaps1, heatmaps2\n",
    "\n",
    "def create_minibatch_test(batch_size):\n",
    "    frames1 = []\n",
    "    heatmaps1 = []\n",
    "    frames2 = []\n",
    "    heatmaps2 = []\n",
    "    for i in range(batch_size):\n",
    "        rand_video = videos_test.keys()[random.randint(0,len(videos_test.keys())-1)]\n",
    "        \n",
    "        rand_int = random.randint(0,len(videos_test[rand_video])-1)\n",
    "        frames1.append(videos_test[rand_video][rand_int])\n",
    "        heatmaps1.append(labels_test[rand_video][rand_int])\n",
    "\n",
    "        rand_int = random.randint(0,len(videos_test[rand_video])-1)\n",
    "        frames2.append(videos_test[rand_video][rand_int])\n",
    "        heatmaps2.append(labels_test[rand_video][rand_int])\n",
    "    return frames1, frames2, heatmaps1, heatmaps2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videos, videos_test, labels, labels_test = process_videos(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, '/media/jeff/WD HDD/CS280/models/gray_skip_middle-99')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "n_samples = 1000\n",
    "batch_size = 4\n",
    "display_step = 1\n",
    "save_model = 50\n",
    "\n",
    "# videos, labels = {},{}\n",
    "mean_gen_losses = []\n",
    "mean_disc_losses = []\n",
    "mod = 0\n",
    "for epoch in range(epochs):\n",
    "    total_iter = n_samples // batch_size\n",
    "    total_gen_loss = 0\n",
    "    total_disc_loss = 0\n",
    "    for i in range(total_iter):\n",
    "        f1,f2,h1,h2 = create_minibatch(batch_size)\n",
    "        gen_loss = generator.fit_batch(sess,h1,h2,f1,f2)\n",
    "        disc_loss = discriminator.fit_batch(sess,h1,h2,f1,f2)\n",
    "        disc_loss = discriminator.fit_batch(sess,h1,h2,f1,f2)\n",
    "        disc_loss = discriminator.fit_batch(sess,h1,h2,f1,f2)\n",
    "        total_gen_loss += gen_loss\n",
    "        total_disc_loss += disc_loss\n",
    "    mean_gen_loss = total_gen_loss / total_iter\n",
    "    mean_disc_loss = total_disc_loss / total_iter\n",
    "    mean_gen_losses.append(mean_gen_loss)\n",
    "    mean_disc_losses.append(mean_disc_loss)\n",
    "    if (epoch + 1) % display_step == 0:\n",
    "        print('epoch %s: gen_loss=%.4f, disc_loss=%.4f' % (epoch + 1, mean_gen_loss, mean_disc_loss))\n",
    "    if (epoch + 1) % save_model == 0:\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, '/media/jeff/WD HDD/CS280/models/gray_skip_middle_111',global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saver = tf.train.Saver()\n",
    "# saver.save(sess, '/media/jeff/WD HDD/CS280/models/gray_13_10_1_1',global_step=108+44)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test = 5\n",
    "for i in range(total_test):\n",
    "    f1,f2,h1,h2 = create_minibatch(3)\n",
    "    gen_img = generator.test_batch(sess,h1,h2,f1,f2)\n",
    "    for i in range(3):\n",
    "        plt.figure(figsize=(15,4))\n",
    "\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(f1[i].reshape((224,224)), cmap = 'gray')\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(f2[i].reshape((224,224)), cmap = 'gray')\n",
    "\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(gen_img[i].reshape((224,224)), cmap = 'gray')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_test = 5\n",
    "for i in range(total_test):\n",
    "    f1,f2,h1,h2 = create_minibatch_test(3)\n",
    "    gen_img = generator.test_batch(sess,h1,h2,f1,f2)\n",
    "    for i in range(3):\n",
    "        plt.figure(figsize=(15,4))\n",
    "\n",
    "        plt.subplot(131)\n",
    "        plt.imshow(f1[i].reshape((224,224)), cmap = 'gray')\n",
    "\n",
    "        plt.subplot(132)\n",
    "        plt.imshow(f2[i].reshape((224,224)), cmap = 'gray')\n",
    "\n",
    "        plt.subplot(133)\n",
    "        plt.imshow(gen_img[i].reshape((224,224)), cmap = 'gray')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
